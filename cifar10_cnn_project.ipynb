{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/M1tn94nWOpz27dq0lXoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahyaHajji/Cifar10_CNN_Project/blob/master/cifar10_cnn_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Import Required Libraries**"
      ],
      "metadata": {
        "id": "I7hT99uV-Dsd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SlJaoIppb4F"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Load and Explore CIFAR-10 Dataset**"
      ],
      "metadata": {
        "id": "S34kPuvbFsKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Class names\n",
        "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
        "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Training images: {x_train.shape}\")\n",
        "print(f\"Training labels: {y_train.shape}\")\n",
        "print(f\"Test images: {x_test.shape}\")\n",
        "print(f\"Test labels: {y_test.shape}\")\n",
        "print(f\"\\nImage shape: {x_train[0].shape}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "print(f\"Pixel value range: [{x_train.min()}, {x_train.max()}]\")\n",
        "\n",
        "# Visualize sample images\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(20):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.title(class_names[y_train[i][0]], fontsize=9)\n",
        "    plt.axis('off')\n",
        "plt.suptitle('CIFAR-10 Sample Images', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4-FaBUQo-Li4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Key differences from MNIST:*\n",
        "\n",
        "*   RGB images (32√ó32√ó3) instead of grayscale\n",
        "*   Real-world objects instead of digits\n",
        "*   More complex patterns to learn\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gGj9vcXcHcl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Data Preprocessing**"
      ],
      "metadata": {
        "id": "2Zdgo5rKG1VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "print(\"After normalization:\")\n",
        "print(f\"Pixel value range: [{x_train.min():.2f}, {x_train.max():.2f}]\")\n",
        "\n",
        "# Flatten labels (from 2D to 1D)\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()\n",
        "\n",
        "print(f\"\\nLabel shapes after flattening:\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n",
        "# Show class distribution\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(class_names, counts, color='steelblue', edgecolor='black')\n",
        "plt.title('Training Data Distribution', fontsize=12, fontweight='bold')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uJ3OqCYI-YlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Build a Simple CNN Model**"
      ],
      "metadata": {
        "id": "LSKO1X_YHMYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Simple CNN\n",
        "simple_cnn = Sequential([\n",
        "    # First Convolutional Block\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Display model architecture\n",
        "simple_cnn.summary()\n",
        "\n",
        "# Calculate total parameters\n",
        "total_params = simple_cnn.count_params()\n",
        "print(f\"\\nüìä Total parameters: {total_params:,}\")"
      ],
      "metadata": {
        "id": "Bwf0H81a-mGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 5: Compile the Model***"
      ],
      "metadata": {
        "id": "ijRHduhWI_3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "simple_cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model compiled successfully!\")"
      ],
      "metadata": {
        "id": "_khZmZN9-pvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Train the Simple CNN**"
      ],
      "metadata": {
        "id": "GzfIqmWoJHrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"üöÄ Training Simple CNN on CIFAR-10...\")\n",
        "start_time = time.time()\n",
        "\n",
        "simple_history = simple_cnn.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "td3B45yK-xfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Build an Advanced CNN with Data Augmentation**"
      ],
      "metadata": {
        "id": "ZHqgUpQPJdtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Build Advanced/Deeper CNN\n",
        "advanced_cnn = Sequential([\n",
        "    # Block 1\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # Block 2\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Block 3\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "advanced_cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display architecture\n",
        "print(\"Advanced CNN Architecture:\")\n",
        "advanced_cnn.summary()\n",
        "\n",
        "print(f\"\\nüìä Total parameters: {advanced_cnn.count_params():,}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sy4GiYKN-3G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Set Up Data Augmentation**"
      ],
      "metadata": {
        "id": "-nuVEqTjKaNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data augmentation generator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,           # Randomly rotate images by 15 degrees\n",
        "    width_shift_range=0.1,       # Shift images horizontally by 10%\n",
        "    height_shift_range=0.1,      # Shift images vertically by 10%\n",
        "    horizontal_flip=True,        # Randomly flip images horizontally\n",
        "    zoom_range=0.1               # Random zoom\n",
        ")\n",
        "\n",
        "# Fit the generator on training data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Visualize augmented images\n",
        "sample_image = x_train[0:1]\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(2, 4, 1)\n",
        "plt.imshow(x_train[0])\n",
        "plt.title('Original', fontweight='bold')\n",
        "plt.axis('off')\n",
        "\n",
        "for i, batch in enumerate(datagen.flow(sample_image, batch_size=1)):\n",
        "    plt.subplot(2, 4, i + 2)\n",
        "    plt.imshow(batch[0])\n",
        "    plt.title(f'Augmented {i+1}')\n",
        "    plt.axis('off')\n",
        "    if i == 6:\n",
        "        break\n",
        "\n",
        "plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Data augmentation configured!\")\n",
        "print(\"This will help the model generalize better and prevent overfitting.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o9UmRL0b_Jbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Train Advanced CNN with Data Augmentation**"
      ],
      "metadata": {
        "id": "58yuhvv_K9Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with data augmentation\n",
        "print(\"üöÄ Training Advanced CNN with Data Augmentation...\")\n",
        "adv_start_time = time.time()\n",
        "\n",
        "advanced_history = advanced_cnn.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=64),\n",
        "    steps_per_epoch=len(x_train) // 64,\n",
        "    epochs=30,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "adv_training_time = time.time() - adv_start_time\n",
        "print(f\"\\n‚è±Ô∏è Training completed in {adv_training_time:.2f} seconds ({adv_training_time/60:.2f} minutes)\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "d7WXZl_n_WFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10: Evaluate Both Models**"
      ],
      "metadata": {
        "id": "mEZazYSnLnyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Simple CNN\n",
        "simple_loss, simple_accuracy = simple_cnn.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Evaluate Advanced CNN\n",
        "adv_loss, adv_accuracy = advanced_cnn.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Display comparison\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä MODEL COMPARISON RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nüü¶ Simple CNN:\")\n",
        "print(f\"   Test Accuracy: {simple_accuracy:.4f} ({simple_accuracy*100:.2f}%)\")\n",
        "print(f\"   Test Loss: {simple_loss:.4f}\")\n",
        "print(f\"   Training Time: {training_time/60:.2f} minutes\")\n",
        "print(f\"   Parameters: {simple_cnn.count_params():,}\")\n",
        "\n",
        "print(f\"\\nüü© Advanced CNN (with Data Augmentation):\")\n",
        "print(f\"   Test Accuracy: {adv_accuracy:.4f} ({adv_accuracy*100:.2f}%)\")\n",
        "print(f\"   Test Loss: {adv_loss:.4f}\")\n",
        "print(f\"   Training Time: {adv_training_time/60:.2f} minutes\")\n",
        "print(f\"   Parameters: {advanced_cnn.count_params():,}\")\n",
        "\n",
        "print(f\"\\n‚ú® Improvement:\")\n",
        "improvement = (adv_accuracy - simple_accuracy) * 100\n",
        "print(f\"   Advanced CNN is {improvement:.2f}% more accurate\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "dMeWFMxM_c8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 11: Visualize Training History**"
      ],
      "metadata": {
        "id": "sV9wzUiwaAkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Simple CNN - Accuracy\n",
        "axes[0, 0].plot(simple_history.history['accuracy'], label='Training', linewidth=2)\n",
        "axes[0, 0].plot(simple_history.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "axes[0, 0].set_title('Simple CNN - Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Accuracy')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Simple CNN - Loss\n",
        "axes[0, 1].plot(simple_history.history['loss'], label='Training', linewidth=2)\n",
        "axes[0, 1].plot(simple_history.history['val_loss'], label='Validation', linewidth=2)\n",
        "axes[0, 1].set_title('Simple CNN - Loss', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Advanced CNN - Accuracy\n",
        "axes[1, 0].plot(advanced_history.history['accuracy'], label='Training', linewidth=2)\n",
        "axes[1, 0].plot(advanced_history.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "axes[1, 0].set_title('Advanced CNN - Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Advanced CNN - Loss\n",
        "axes[1, 1].plot(advanced_history.history['loss'], label='Training', linewidth=2)\n",
        "axes[1, 1].plot(advanced_history.history['val_loss'], label='Validation', linewidth=2)\n",
        "axes[1, 1].set_title('Advanced CNN - Loss', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NSYhkH9i_jj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 12: Model Comparison Bar Chart**"
      ],
      "metadata": {
        "id": "VsrQFzQ0aN4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create comparison bar chart\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy comparison\n",
        "models = ['Simple CNN', 'Advanced CNN\\n(+ Augmentation)']\n",
        "accuracies = [simple_accuracy * 100, adv_accuracy * 100]\n",
        "colors = ['#FF6B6B', '#4ECDC4']\n",
        "\n",
        "bars1 = ax1.bar(models, accuracies, color=colors, width=0.6, edgecolor='black', linewidth=2)\n",
        "for bar, acc in zip(bars1, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{acc:.2f}%',\n",
        "            ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax1.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylim([60, 85])\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Parameter comparison\n",
        "params = [simple_cnn.count_params()/1e6, advanced_cnn.count_params()/1e6]\n",
        "bars2 = ax2.bar(models, params, color=colors, width=0.6, edgecolor='black', linewidth=2)\n",
        "for bar, param in zip(bars2, params):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{param:.2f}M',\n",
        "            ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax2.set_ylabel('Parameters (Millions)', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Model Complexity Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FlJ4OIBh_mah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 13: Test Predictions with Visualization**"
      ],
      "metadata": {
        "id": "oDXCJebZaT_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test set\n",
        "predictions = advanced_cnn.predict(x_test[:30])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Visualize predictions\n",
        "fig, axes = plt.subplots(5, 6, figsize=(15, 12))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(x_test[i])\n",
        "\n",
        "    true_label = y_test[i]\n",
        "    pred_label = predicted_classes[i]\n",
        "    confidence = predictions[i][pred_label] * 100\n",
        "\n",
        "    # Color code: green if correct, red if wrong\n",
        "    if pred_label == true_label:\n",
        "        color = 'green'\n",
        "        border_color = 'lightgreen'\n",
        "    else:\n",
        "        color = 'red'\n",
        "        border_color = 'lightcoral'\n",
        "\n",
        "    ax.set_title(f'True: {class_names[true_label]}\\n'\n",
        "                 f'Pred: {class_names[pred_label]}\\n'\n",
        "                 f'Conf: {confidence:.1f}%',\n",
        "                 color=color, fontsize=9, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Add colored border\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_edgecolor(border_color)\n",
        "        spine.set_linewidth(3)\n",
        "        spine.set_visible(True)\n",
        "\n",
        "plt.suptitle('Advanced CNN Predictions on CIFAR-10 Test Set',\n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nxGI08nO_q87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 14: Confusion Matrix**"
      ],
      "metadata": {
        "id": "ix3b4mHyacdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Get all predictions\n",
        "all_predictions = advanced_cnn.predict(x_test)\n",
        "predicted_classes_all = np.argmax(all_predictions, axis=1)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, predicted_classes_all)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar_kws={'label': 'Number of Predictions'})\n",
        "plt.title('Advanced CNN Confusion Matrix - CIFAR-10',\n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
        "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nüìä Advanced CNN Classification Report:\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, predicted_classes_all,\n",
        "                           target_names=class_names, digits=4))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6CXOuNHO_utI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 15: Per-Class Accuracy Analysis**"
      ],
      "metadata": {
        "id": "N6O7G_-takyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate per-class accuracy\n",
        "class_correct = np.zeros(10)\n",
        "class_total = np.zeros(10)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    true_label = y_test[i]\n",
        "    pred_label = predicted_classes_all[i]\n",
        "    class_total[true_label] += 1\n",
        "    if true_label == pred_label:\n",
        "        class_correct[true_label] += 1\n",
        "\n",
        "class_accuracy = (class_correct / class_total) * 100\n",
        "\n",
        "# Sort by accuracy\n",
        "sorted_indices = np.argsort(class_accuracy)\n",
        "\n",
        "# Plot per-class accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "colors_bars = ['red' if acc < 70 else 'orange' if acc < 80 else 'green'\n",
        "               for acc in class_accuracy[sorted_indices]]\n",
        "\n",
        "bars = plt.barh([class_names[i] for i in sorted_indices],\n",
        "                class_accuracy[sorted_indices],\n",
        "                color=colors_bars, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, acc) in enumerate(zip(bars, class_accuracy[sorted_indices])):\n",
        "    plt.text(acc + 1, i, f'{acc:.1f}%',\n",
        "             va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.xlabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "plt.title('Per-Class Accuracy - Advanced CNN on CIFAR-10',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.xlim([0, 105])\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print analysis\n",
        "print(\"\\nüéØ Per-Class Performance Analysis:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Best performing class: {class_names[np.argmax(class_accuracy)]} ({class_accuracy.max():.2f}%)\")\n",
        "print(f\"Worst performing class: {class_names[np.argmin(class_accuracy)]} ({class_accuracy.min():.2f}%)\")\n",
        "print(f\"Average accuracy: {class_accuracy.mean():.2f}%\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "_37ZCDnD_zRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 16: Most Confused Class Pairs**"
      ],
      "metadata": {
        "id": "s6eF1rFpaqMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find most confused pairs\n",
        "confusion_pairs = []\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        if i != j:\n",
        "            confusion_pairs.append((i, j, cm[i][j]))\n",
        "\n",
        "# Sort by confusion count\n",
        "confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "# Display top 10 most confused pairs\n",
        "print(\"\\nüîÄ Top 10 Most Confused Class Pairs:\")\n",
        "print(\"=\"*60)\n",
        "for idx, (true_class, pred_class, count) in enumerate(confusion_pairs[:10], 1):\n",
        "    print(f\"{idx:2d}. {class_names[true_class]:12s} ‚Üí {class_names[pred_class]:12s}: {count:4d} times\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Visualize some confused examples\n",
        "most_confused = confusion_pairs[0]\n",
        "true_idx, pred_idx = most_confused[0], most_confused[1]\n",
        "\n",
        "# Find examples of this confusion\n",
        "confused_examples = []\n",
        "for i in range(len(y_test)):\n",
        "    if y_test[i] == true_idx and predicted_classes_all[i] == pred_idx:\n",
        "        confused_examples.append(i)\n",
        "        if len(confused_examples) >= 10:\n",
        "            break\n",
        "\n",
        "if confused_examples:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    for i, idx in enumerate(confused_examples[:10]):\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(x_test[idx])\n",
        "        conf = all_predictions[idx][pred_idx] * 100\n",
        "        plt.title(f'True: {class_names[true_idx]}\\n'\n",
        "                  f'Pred: {class_names[pred_idx]}\\n'\n",
        "                  f'{conf:.1f}%',\n",
        "                  fontsize=9, color='red', fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Most Common Confusion: {class_names[true_idx]} ‚Üí {class_names[pred_idx]}',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "k31yyk46_209"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 17: Save the Best Model**"
      ],
      "metadata": {
        "id": "lDH_Icg7azSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the advanced model\n",
        "model_path = 'cifar10_advanced_cnn.h5'\n",
        "advanced_cnn.save(model_path)\n",
        "print(f\"‚úÖ Model saved to: {model_path}\")\n",
        "\n",
        "# You can also save to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save to Drive\n",
        "drive_path = '/content/drive/MyDrive/cifar10_advanced_cnn.h5'\n",
        "advanced_cnn.save(drive_path)\n",
        "print(f\"‚úÖ Model also saved to Google Drive: {drive_path}\")\n",
        "\n",
        "# To load later:\n",
        "# from tensorflow.keras.models import load_model\n",
        "# loaded_model = load_model('cifar10_advanced_cnn.h5')"
      ],
      "metadata": {
        "id": "N-WJ_d02_8IR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}